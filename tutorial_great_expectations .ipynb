{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations tutorial\n",
    "Welcome! In this tutorial we'll have a look at Great Expectations, a tool written and configured in Python that aids you in keeping an eye on your data quality. It provides a batteries-included solution for testing and documenting your data, so that nobody has to run into any surprises when consuming it. To achieve this, you create _expectation suites_. You can think of them as unit tests, but for data. They also double as documentation for your dataset, so that you won't have to repeat yourself.\n",
    "\n",
    "What do we mean by data quality? Well, bad quality data can happen for different reasons. Usually, data has bad quality if its structure (for example the columns and their types in a table) or its contents (specific cells in a table) are not what you expected.\n",
    "\n",
    "For more background on Great Expectations and the problems it solves, we can recommend the authors' blogpost: [Down with Pipeline debt / Introducing Great Expectations](https://medium.com/@expectgreatdata/down-with-pipeline-debt-introducing-great-expectations-862ddc46782a). It's a good read!\n",
    "\n",
    "## What is Great Expectations exactly?\n",
    "\n",
    "<img src='figures/in_out.png' width=800px>\n",
    "\n",
    "Great Expectations can be used with your existing data assets - it is able to use different backends such as SQL databases, Spark clusters, or just your plain old filesystem. It will execute your expectation suites on these backends, and generate reports on the results of your validation.  \n",
    "Writing your expectation suite is usually done through Jupyter notebooks, so you'll feel at home. This notebook itself would be an example of how that works!\n",
    "\n",
    "\n",
    "## In this tutorial\n",
    "We'll give you a brief introduction to the main concepts used in Great Expectations, walking you through writing your first expectations and generating your first data report. We have added many references to the official documentation that you can reference to when you are configuring your own setup.\n",
    "\n",
    "Contents:\n",
    "- [Getting started](#section-getting-started)\n",
    "- [The Expectation Suite](#section-expectation-suite)\n",
    "- [Data Docs](#section-data-docs)\n",
    "- [Data Context](#section-data-context)\n",
    "- [Checkpoints](#section-checkpoints)\n",
    "- [Data Profiling](#section-profiling)\n",
    "- [The Great Expectations CLI](#section-cli)\n",
    "- [Setting up your own project](#section-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import great_expectations as ge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir great_expectations/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(startpath, skip_folder='uncommitted'):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        if skip_folder not in root:\n",
    "            level = root.replace(startpath, '').count(os.sep)\n",
    "            indent = ' ' * 4 * (level)\n",
    "            print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "            subindent = ' ' * 4 * (level + 1)\n",
    "            for f in files:\n",
    "                print('{}{}'.format(subindent, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need a `DataContext`. This represents a Great Expectations project, holding all your configurations, expectation suites, data sources and so on. We'll have a better look at the data context later [[Data Context]](#section-data-context), but just to get started we shipped a simple one with this tutorial.\n",
    "\n",
    "We'll load that one right now. By default, Great Expectations will look for your configuration in the `great_expectations` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `DataContext` ready, we can add an expectation suite. Think of this like a test suite, but for your data instead of for your code. Usually you'll do this through the CLI, but we will get to that later [[The Great Expectations CLI]](#section-cli). We'll name the suite `check_avocado_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = context.create_expectation_suite(\n",
    "    'check_avocado_data',\n",
    "    overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our dataset, `avocado.csv`, from our data context. This involves a bit of configuration, but don't worry about it too much for now. We'll get back to that later [[Data Context]](#section-data-context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {\n",
    "    'path': 'data/avocado.csv',\n",
    "    'datasource': 'data_dir',\n",
    "    'data_asset_name': 'avocado',\n",
    "    'reader_method': 'read_csv',\n",
    "    'reader_options': {\n",
    "        'index_col': 0,\n",
    "    }\n",
    "}\n",
    "batch = context.get_batch(batch_kwargs, suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that's it for setup!\n",
    "\n",
    "Let's continue to our avocado sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the documentation that came with the data:\n",
    " - Date - The date of the observation\n",
    " - AveragePrice - the average price of a single avocado\n",
    " - type - agriculture type: conventional or organic\n",
    " - Region - the city or region of the observation\n",
    " - Total Volume - Total number of avocados sold\n",
    " - 4046 - Total number of avocados with PLU 4046 sold (small Hass)\n",
    " - 4225 - Total number of avocados with PLU 4225 sold (large Hass)\n",
    " - 4770 - Total number of avocados with PLU 4770 sold (extra large Hass)\n",
    " \n",
    "These descriptions sure help us to understand the dataset a bit better, but they don't exactly provide much guarantees. When consuming this dataset, what expectations can we have? Will the `region` field always be specified? Will the `Date` field always be in the same format? Those sales counts, are they supposed to add up?\n",
    "\n",
    "Great Expectations helps us to codify these properties in a set of `Expectations`. An `Expectation` is, well, something that you expect to be true in your data. Again, think of it as an unit test for your dataset.\n",
    "\n",
    "Let's run a basic `Expectation` to get started. We want to check whether our expectation that the Date column is present holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {},\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_to_exist('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `dict` we got back might feel a bit weird at first, but you'll see later on how this output is used to generate reports [[Data Docs]](#section-data-docs). For now, just note that `success` has the value `true`, indicating that our expectation passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple check that only assesses the data shape, but doesn't touch the values in there (it is a _table-level check_).\n",
    "\n",
    "Let's try adding a check for the values now. Maybe we can address one of the concerns we raised: can we add an `Expectation` that ensures every record will have its `region` specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_not_be_null('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! This time we got a bit more info back: the `result` section now contains some metrics about our data. We can see that all 18249 records passed the check, and there were no unexpected (i.e. `null`) values. If Great Expectations finds any offending values, they will be listed in the `partial_unexpected_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do something that's a bit more strict. It would be nice, for example, to make sure that all `region`s are actually strings, so that we don't end up with numeric regions. Note that the type you specify here should match your backend - you can't expect a spark backend to have PostgresQL types. Refer to [the documentation](https://greatexpectations.io/expectations/expect_column_values_to_be_of_type) to see what type name you should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_of_type('region', 'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that metrics on the amount of missing values were still collected. This way, we can disambiguate between missing values and incorrect values. In case you were wondering, the `unexpected_percent_nonmissing` refers to the percentage of present (non-null) values that did not meet our expectation (they were not a string). If other metrics are unclear to you, check out [this documentation page](https://docs.greatexpectations.io/en/latest/reference/core_concepts/expectations/result_format.html#behavior-for-summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we covered the basics, let's get to some fancier expectations. For example, we could make sure that all `Date`s are in the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_match_strftime_format('Date', \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: we can make sure all the listed avocado prices are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! That failed. Looks like we have some outliers here! Great Expectations helpfully collected them for us. By default, it will collect up to 20 examples of values that didn't meet the expectation (that's why it's called the _partial_ unexpected list).\n",
    "\n",
    "If we want to allow these outliers, we can add some tolerance to the check by using the `mostly` parameter. Let's replace that expecation with a new one, that only expects 99% of avocados being priced within the range we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common usecase would be when you only expect a certain set of values to show up in a column. This is the case for our `type` column, since we only know about `conventional` and `organic` grown avocados. Let's add a check for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"conventional\",\n",
       "      \"organic\"\n",
       "    ],\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_distinct_values_to_be_in_set('type', ['conventional', 'organic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even add a check on the value frequencies! For example, if we want the ratio of organic to conventional to be roughly equal, we could check the [Kullback-Leiber divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between our assumed distribution, and the one that is observed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1.351245850704074e-08,\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_object = {\n",
    "    'values': ['conventional', 'organic'],\n",
    "    'weights': [0.5, 0.5],\n",
    "    \n",
    "}\n",
    "batch.expect_column_kl_divergence_to_be_less_than('type', partition_object, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we checked out some expectations, maybe try adding one yourself? You can check out the [glossary of expectations](https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html) for a complete list of what you can do. Go wild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stage is all yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-expectation-suite\"></a>\n",
    "## The Expectation Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we were experimenting up there, great_expectations remembered all the expectations we ran. We can now retrieve the suite contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"expectation_suite_name\": \"check_avocado_data\",\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_to_exist\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\",\n",
       "        \"strftime_format\": \"%Y-%m-%d\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"AveragePrice\",\n",
       "        \"min_value\": 0.5,\n",
       "        \"max_value\": 3.0,\n",
       "        \"mostly\": 0.99\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"value_set\": [\n",
       "          \"conventional\",\n",
       "          \"organic\"\n",
       "        ]\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"partition_object\": {\n",
       "          \"values\": [\n",
       "            \"conventional\",\n",
       "            \"organic\"\n",
       "          ],\n",
       "          \"weights\": [\n",
       "            0.5,\n",
       "            0.5\n",
       "          ]\n",
       "        },\n",
       "        \"threshold\": 0.1\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "      \"meta\": {}\n",
       "    }\n",
       "  ],\n",
       "  \"data_asset_type\": \"Dataset\",\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.13.5\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us the `dict` representation Great Expectations uses under the hood to keep track of our exepectation suite. Can you recognise some of the expectations we wrote?\n",
    "\n",
    "An expectation suite is just a sequence of expectations, as shown below.\n",
    "<img src=\"figures/expectation_suite.png\">\n",
    "This representation can then be saved to a file, so that we can load it again at another time, without depending on the python code that produced it.\n",
    "\n",
    "Note that by default, expectations that failed on the `batch` we ran them against will be omitted. If you want to include them anyways, you could add the `discard_failed_expectations=False` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that command do? Let's open up our configuration folder to try and find our expectation suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ge_store_backend_id', 'check_avocado_data.json']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('great_expectations/expectations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get back to the configuration in a minute [[Data Context]](#section-data-context), so don't get confused about this yet.\n",
    "\n",
    "As you can see, the `save_expectation_suite` command saved our `check_avocado_data` suite to the `expectations` folder. That's all there is to it, the expectation suite is just a json file. It contains that same internal representation that we retrieved from `get_expectation_suite()`. You can check it out if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_asset_type\": \"Dataset\",\n",
      "  \"expectation_suite_name\": \"check_avocado_data\",\n",
      "  \"expectations\": [\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_to_exist\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"Date\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"region\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"region\",\n",
      "        \"type_\": \"str\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"Date\",\n",
      "        \"strftime_format\": \"%Y-%m-%d\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_values_to_be_between\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"AveragePrice\",\n",
      "        \"max_value\": 3.0,\n",
      "        \"min_value\": 0.5,\n",
      "        \"mostly\": 0.99\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"type\",\n",
      "        \"value_set\": [\n",
      "          \"conventional\",\n",
      "          \"organic\"\n",
      "        ]\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    {\n",
      "      \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"type\",\n",
      "        \"partition_object\": {\n",
      "          \"values\": [\n",
      "            \"conventional\",\n",
      "            \"organic\"\n",
      "          ],\n",
      "          \"weights\": [\n",
      "            0.5,\n",
      "            0.5\n",
      "          ]\n",
      "        },\n",
      "        \"threshold\": 0.1\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"meta\": {\n",
      "    \"great_expectations_version\": \"0.13.5\"\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat great_expectations/expectations/check_avocado_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectations are stored in the *expectation store*, which by default is the `expectations` folder inside your configuration, but you can use other storage backends as well, such as a SQL database or cloud storage (S3, Azure Blob Storage or GCS). See [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validation-results\"></a>\n",
    "Now that we added our expectation suite to our `DataContext`, we can try running the entire suite.\n",
    "Validiating your data against an expectation suite is done by running a **validation operator**. A validation operator describes what should be done with your validation results. Here, we would like to store the results on disk, and generate a friendly report on them. We'll show you how this is configured in the [Data Context section](#section-data-context), in the meanwhile we'll use `my_validation_operator`, which we shipped with the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = context.run_validation_operator('my_validation_operator', assets_to_validate=[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One validation run can include multiple batches and expectation suites. This way, it is possible to test multiple files in the same run. Compare this to how one run of your test suite can test multiple software modules.\n",
    "\n",
    "We didn't explicitly specify the expectation suite to use with our data batch, because `batch` keeps track of the expectation suite for us. We already saw this when we retrieved the suite from it at the beginning of this section.\n",
    "\n",
    "Now that we got through that, let's have a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"evaluation_parameters\": null,\n",
       "  \"success\": true,\n",
       "  \"run_results\": {\n",
       "    \"ValidationResultIdentifier::check_avocado_data/20230720T131914.617041Z/20230720T131914.617041Z/966da3deeba5d9b2be246213aa75e7b7\": {\n",
       "      \"validation_result\": {\n",
       "        \"evaluation_parameters\": {},\n",
       "        \"success\": true,\n",
       "        \"statistics\": {\n",
       "          \"evaluated_expectations\": 7,\n",
       "          \"successful_expectations\": 7,\n",
       "          \"unsuccessful_expectations\": 0,\n",
       "          \"success_percent\": 100.0\n",
       "        },\n",
       "        \"results\": [\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_to_exist\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {},\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"strftime_format\": \"%Y-%m-%d\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"partial_unexpected_list\": []\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"type_\": \"str\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"AveragePrice\",\n",
       "                \"min_value\": 0.5,\n",
       "                \"max_value\": 3.0,\n",
       "                \"mostly\": 0.99,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 11,\n",
       "              \"unexpected_percent\": 0.06027727546714888,\n",
       "              \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "              \"partial_unexpected_list\": [\n",
       "                0.49,\n",
       "                0.46,\n",
       "                3.03,\n",
       "                3.12,\n",
       "                3.25,\n",
       "                0.44,\n",
       "                0.49,\n",
       "                0.48,\n",
       "                3.05,\n",
       "                3.04,\n",
       "                3.17\n",
       "              ],\n",
       "              \"partial_unexpected_index_list\": [\n",
       "                0,\n",
       "                47,\n",
       "                12,\n",
       "                7,\n",
       "                8,\n",
       "                43,\n",
       "                44,\n",
       "                43,\n",
       "                42,\n",
       "                18,\n",
       "                37\n",
       "              ],\n",
       "              \"partial_unexpected_counts\": [\n",
       "                {\n",
       "                  \"value\": 0.49,\n",
       "                  \"count\": 2\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.44,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.46,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.48,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.03,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.04,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.05,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.12,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.17,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.25,\n",
       "                  \"count\": 1\n",
       "                }\n",
       "              ]\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"value_set\": [\n",
       "                  \"conventional\",\n",
       "                  \"organic\"\n",
       "                ],\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"observed_value\": [\n",
       "                \"conventional\",\n",
       "                \"organic\"\n",
       "              ],\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"value_counts\": [\n",
       "                  {\n",
       "                    \"value\": \"conventional\",\n",
       "                    \"count\": 9126\n",
       "                  },\n",
       "                  {\n",
       "                    \"value\": \"organic\",\n",
       "                    \"count\": 9123\n",
       "                  }\n",
       "                ]\n",
       "              }\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          },\n",
       "          {\n",
       "            \"success\": true,\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"partition_object\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                },\n",
       "                \"threshold\": 0.1,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"result\": {\n",
       "              \"observed_value\": 1.351245850704074e-08,\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"observed_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5000821962847279,\n",
       "                    0.49991780371527206\n",
       "                  ]\n",
       "                },\n",
       "                \"expected_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"meta\": {}\n",
       "          }\n",
       "        ],\n",
       "        \"meta\": {\n",
       "          \"great_expectations_version\": \"0.13.5\",\n",
       "          \"expectation_suite_name\": \"check_avocado_data\",\n",
       "          \"run_id\": {\n",
       "            \"run_time\": \"2023-07-20T13:19:14.617041+00:00\",\n",
       "            \"run_name\": \"20230720T131914.617041Z\"\n",
       "          },\n",
       "          \"batch_kwargs\": {\n",
       "            \"path\": \"data/avocado.csv\",\n",
       "            \"datasource\": \"data_dir\",\n",
       "            \"data_asset_name\": \"avocado\",\n",
       "            \"reader_method\": \"read_csv\",\n",
       "            \"reader_options\": {\n",
       "              \"index_col\": 0\n",
       "            }\n",
       "          },\n",
       "          \"batch_markers\": {\n",
       "            \"ge_load_time\": \"20230720T131914.137556Z\",\n",
       "            \"pandas_data_fingerprint\": \"4607eba0540868ca4fb1448026bad09c\"\n",
       "          },\n",
       "          \"batch_parameters\": null,\n",
       "          \"validation_time\": \"20230720T131914.617374Z\"\n",
       "        }\n",
       "      },\n",
       "      \"actions_results\": {\n",
       "        \"store_validation_result\": {\n",
       "          \"class\": \"StoreValidationResultAction\"\n",
       "        },\n",
       "        \"update_data_docs\": {\n",
       "          \"local_site\": \"file:///Users/quentin.soulet/Documents/Projects/formation/AIclinic-TotalEnergies-tutoQA/great_expectations/uncommitted/data_docs/local_site/validations/check_avocado_data/20230720T131914.617041Z/20230720T131914.617041Z/966da3deeba5d9b2be246213aa75e7b7.html\",\n",
       "          \"class\": \"UpdateDataDocsAction\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"validation_operator_config\": {\n",
       "    \"class_name\": \"ActionListValidationOperator\",\n",
       "    \"module_name\": \"great_expectations.validation_operators\",\n",
       "    \"name\": \"my_validation_operator\",\n",
       "    \"kwargs\": {\n",
       "      \"action_list\": [\n",
       "        {\n",
       "          \"name\": \"store_validation_result\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"StoreValidationResultAction\"\n",
       "          }\n",
       "        },\n",
       "        {\n",
       "          \"name\": \"update_data_docs\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"UpdateDataDocsAction\"\n",
       "          }\n",
       "        }\n",
       "      ],\n",
       "      \"result_format\": {\n",
       "        \"result_format\": \"SUMMARY\",\n",
       "        \"partial_unexpected_count\": 20\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"run_id\": {\n",
       "    \"run_time\": \"2023-07-20T13:19:14.617041+00:00\",\n",
       "    \"run_name\": \"20230720T131914.617041Z\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *validation result*. Validation results are kept in the *validation store*, which is the `great_expectations/uncommitted/validations` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m20230720T131914.617041Z\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls great_expectations/uncommitted/validations/check_avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great Expectations also allows you to set other backends as a validation store, such as your favourite cloud storage offering, or a SQL database. Check out [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you would like to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-docs\"></a>\n",
    "## Data Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render these results to a friendly report, called a data doc. These data docs will describe the expectations that the data should meet, as well as the metrics detailing how well the data meets the requirements. This is how Great Expectations combines testing with documenting.\n",
    "\n",
    "Remember that we already built the data docs using `my_validation_operator` in the previous section. Let's check them out now! We'll take you to the index page, make sure to browse around for a bit. In the `Validation Results` tab you'll find the validation run we ran above. Click it for a friendly report on its results. In the `Expectation Suites` tab, you can find a document detailing the expectations set by our `check_avocado_data` suite. You'll see the expectations we ran above reflected in the different sections.\n",
    "\n",
    "If you are running the tutorial on your OS, run this command to open the data docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running on docker, try this link [here](/view/great_expectations/uncommitted/data_docs/local_site/index.html). If the links don't work in your browser, you could try using the [jupyter file browser](/tree/great_expectations/uncommitted/data_docs/local_site). It's not ideal, but it works. \n",
    "\n",
    "Otherwise, you can view the results for our run [here](https://datarootsio.github.io/tutorial-great-expectations/validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for validation results, different storage backends can be configured for your data docs. You could, for example, host them on cloud storage for easy viewing. Refer to [configuring data docs](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_data_docs.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-context\"></a>\n",
    "## Data Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's take a moment to look at the `DataContext`, which represents your Great Expectations setup. It consists of a directory holding configuration files, named `great_expectations` by default.\n",
    "\n",
    "Note: we are omitting the `uncommitted` directory here. It contains output files (such as rendered data docs), which are not part of the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great_expectations/\n",
      "    great_expectations.yml\n",
      "    .gitignore\n",
      "    plugins/\n",
      "        custom_data_docs/\n",
      "            styles/\n",
      "                data_docs_custom_styles.css\n",
      "    checkpoints/\n",
      "    expectations/\n",
      "        .ge_store_backend_id\n",
      "        check_avocado_data.json\n",
      "    notebooks/\n",
      "        spark/\n",
      "            validation_playground.ipynb\n",
      "        pandas/\n",
      "            validation_playground.ipynb\n",
      "        sql/\n",
      "            validation_playground.ipynb\n"
     ]
    }
   ],
   "source": [
    "list_files('great_expectations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main configuration is located in `great_expectations.yml`. We won't go into all the details here, you can refer to the [data context reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/data_context_reference.html) for that. Instead, we'll just introduce some concepts you'll want to be familiar with:\n",
    "\n",
    "- A **data source** is something that can provide data to Great Expectations, such as an SQL database.\n",
    "- A **data asset** is one dataset that lives in a *data source*, such as an SQL table.\n",
    "\n",
    "In the configuration we provided, there is one *data source* named `data_dir`, which is just a folder with csv files inside. the `avocado.csv` file we are working with would be a *data asset*.\n",
    "More information on data sources can be found in the [data context reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/data_context_reference.html#datasources). For configuring your own, refer to the [configuring datasources](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_datasources.html) guides.\n",
    "\n",
    "- A **validation operator** specifies what should be done with your validation results. Some examples could be writing the validation results to a database, publishing data docs, or sending a notification to a slack channel.\n",
    "    If you'd like to know more you can check out the [validation operators and actions](https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation_operators_and_actions.html) and [how to add a validation operator](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation/how_to_add_a_validation_operator.html) documentation pages.\n",
    "\n",
    "\n",
    "- **stores** can be used to configure how expectation and validation data will be stored. See [configuring metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you're interested.\n",
    "\n",
    "These are all configured in the `great_expectations.yml` file. We'll have a brief look at its contents now, but don't mind it too much, this is here for illustration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Welcome to Great Expectations! Always know what to expect from your data.\n",
      "#\n",
      "# Here you can define datasources, batch kwargs generators, integrations and\n",
      "# more. This file is intended to be committed to your repo. For help with\n",
      "# configuration please:\n",
      "#   - Read our docs: https://docs.greatexpectations.io/en/latest/how_to_guides/spare_parts/data_context_reference.html#configuration\n",
      "#   - Join our slack channel: http://greatexpectations.io/slack\n",
      "\n",
      "# config_version refers to the syntactic version of this config file, and is used in maintaining backwards compatibility\n",
      "# It is auto-generated and usually does not need to be changed.\n",
      "config_version: 2.0\n",
      "\n",
      "# Datasources tell Great Expectations where your data lives and how to get it.\n",
      "# You can use the CLI command `great_expectations datasource new` to help you\n",
      "# add a new datasource. Read more at https://docs.greatexpectations.io/en/latest/reference/core_concepts/datasource_reference.html\n",
      "datasources:\n",
      "  data_dir:\n",
      "    batch_kwargs_generators:\n",
      "      subdir_reader:\n",
      "        class_name: SubdirReaderBatchKwargsGenerator\n",
      "        base_directory: ../data\n",
      "    module_name: great_expectations.datasource\n",
      "    data_asset_type:\n",
      "      module_name: great_expectations.dataset\n",
      "      class_name: PandasDataset\n",
      "    class_name: PandasDatasource\n",
      "\n",
      "# This config file supports variable substitution which enables: 1) keeping\n",
      "# secrets out of source control & 2) environment-based configuration changes\n",
      "# such as staging vs prod.\n",
      "#\n",
      "# When GE encounters substitution syntax (like `my_key: ${my_value}` or\n",
      "# `my_key: $my_value`) in the great_expectations.yml file, it will attempt\n",
      "# to replace the value of `my_key` with the value from an environment\n",
      "# variable `my_value` or a corresponding key read from this config file,\n",
      "# which is defined through the `config_variables_file_path`.\n",
      "# Environment variables take precedence over variables defined here.\n",
      "#\n",
      "# Substitution values defined here can be a simple (non-nested) value,\n",
      "# nested value such as a dictionary, or an environment variable (i.e. ${ENV_VAR})\n",
      "#\n",
      "#\n",
      "# https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_data_contexts/how_to_use_a_yaml_file_or_environment_variables_to_populate_credentials.html\n",
      "\n",
      "\n",
      "config_variables_file_path: uncommitted/config_variables.yml\n",
      "\n",
      "# The plugins_directory will be added to your python path for custom modules\n",
      "# used to override and extend Great Expectations.\n",
      "plugins_directory: plugins/\n",
      "\n",
      "# Validation Operators are customizable workflows that bundle the validation of\n",
      "# one or more expectation suites and subsequent actions. The example below\n",
      "# stores validations and send a slack notification. To read more about\n",
      "# customizing and extending these, read: https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation_operators_and_actions.html\n",
      "validation_operators:\n",
      "  my_validation_operator:\n",
      "    # To learn how to configure sending Slack notifications during evaluation\n",
      "    # (and other customizations), read: https://docs.greatexpectations.io/en/latest/autoapi/great_expectations/validation_operators/index.html#great_expectations.validation_operators.ActionListValidationOperator\n",
      "    class_name: ActionListValidationOperator\n",
      "    action_list:\n",
      "    - name: store_validation_result\n",
      "      action:\n",
      "        class_name: StoreValidationResultAction\n",
      "    - name: update_data_docs\n",
      "      action:\n",
      "        class_name: UpdateDataDocsAction\n",
      "\n",
      "stores:\n",
      "# Stores are configurable places to store things like Expectations, Validations\n",
      "# Data Docs, and more. These are for advanced users only - most users can simply\n",
      "# leave this section alone.\n",
      "#\n",
      "# Three stores are required: expectations, validations, and\n",
      "# evaluation_parameters, and must exist with a valid store entry. Additional\n",
      "# stores can be configured for uses such as data_docs, validation_operators, etc.\n",
      "  expectations_store:\n",
      "    class_name: ExpectationsStore\n",
      "    store_backend:\n",
      "      class_name: TupleFilesystemStoreBackend\n",
      "      base_directory: expectations/\n",
      "\n",
      "  validations_store:\n",
      "    class_name: ValidationsStore\n",
      "    store_backend:\n",
      "      class_name: TupleFilesystemStoreBackend\n",
      "      base_directory: uncommitted/validations/\n",
      "\n",
      "  evaluation_parameter_store:\n",
      "    # Evaluation Parameters enable dynamic expectations. Read more here:\n",
      "    # https://docs.greatexpectations.io/en/latest/reference/core_concepts/evaluation_parameters.html\n",
      "    class_name: EvaluationParameterStore\n",
      "\n",
      "expectations_store_name: expectations_store\n",
      "validations_store_name: validations_store\n",
      "evaluation_parameter_store_name: evaluation_parameter_store\n",
      "\n",
      "data_docs_sites:\n",
      "  # Data Docs make it simple to visualize data quality in your project. These\n",
      "  # include Expectations, Validations & Profiles. The are built for all\n",
      "  # Datasources from JSON artifacts in the local repo including validations &\n",
      "  # profiles from the uncommitted directory. Read more at https://docs.greatexpectations.io/en/latest/reference/core_concepts/data_docs.html\n",
      "  local_site:\n",
      "    class_name: SiteBuilder\n",
      "    # set to false to hide how-to buttons in Data Docs\n",
      "    show_how_to_buttons: true\n",
      "    store_backend:\n",
      "      class_name: TupleFilesystemStoreBackend\n",
      "      base_directory: uncommitted/data_docs/local_site/\n",
      "    site_index_builder:\n",
      "      class_name: DefaultSiteIndexBuilder\n",
      "\n",
      "anonymous_usage_statistics:\n",
      "  data_context_id: 95d69e85-c578-4eae-9368-efa33a7304c5\n",
      "  enabled: true\n",
      "notebooks:\n"
     ]
    }
   ],
   "source": [
    "!cat great_expectations/great_expectations.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we also have two important directories: `expectations`, which holds our expectation suites, and `checkpoints`, which we'll check out next.\n",
    "\n",
    "The diagram below shows a representation of our data context.\n",
    "<img src=\"figures/data_context.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-checkpoints\"></a>\n",
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we launched a validation run back in the [Expectation Suite section](#section-expectation-suite). There, we wrote code to run the validation on the data batch and expectation suite that we defined earlier on. If we bundle all these run parameters in a single configuration file, we could easily rerun the validation, for example each time our data changes. Such a configuration file is called a `Checkpoint` in Great Expectations.\n",
    "\n",
    "As a quick reminder, for running a validation we need:\n",
    "- A *validation operator* to handle the validation results\n",
    "- A list of *batches*, each consisting of\n",
    "    - A batch of data to check\n",
    "    - expectation suites to check against\n",
    "    \n",
    "To create a checkpoint, we simply create a file in the `checkpoints` directory of our great_expectations configuration. We'll create the file manually now for demonstration purposes, but when doing this in your own project you probably want to use the CLI [[The Great Expectations CLI]](#section-cli), which will help you along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing great_expectations/checkpoints/avocado_data.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile great_expectations/checkpoints/avocado_data.yml\n",
    "\n",
    "validation_operator_name: my_validation_operator\n",
    "batches:\n",
    "  - batch_kwargs:\n",
    "      path: data/avocado.csv\n",
    "      datasource: data_dir\n",
    "      data_asset_name: avocado\n",
    "      reader_method: read_csv\n",
    "      reader_options:\n",
    "        index_col: 0\n",
    "    expectation_suite_names:\n",
    "      - check_avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `batch_kwargs` property specifies how the data asset should be loaded. You might recognise the parameters from when we first loaded the `avocado.csv` file.\n",
    "\n",
    "This might also be a good time to point out that our data batch will get read by pandas under the hood (we configured that in the `data_dir` data source). In `batch_kwargs`, we specify that we'd like to use the pandas `read_csv` method, which will receive the `reader_options` dict as additional parameters.\n",
    "For more information on batches, check out the [creating batches](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/creating_batches.html) guide.\n",
    "\n",
    "The checkpoint can be executed by using the great_expectations cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHeads up! This feature is Experimental. It may change. Please give us your feedback!\u001b[0m\u001b[0m\n",
      "Validation succeeded!\u001b[0m\n",
      "\n",
      "Suite Name                                   Status     Expectations met\u001b[0m\n",
      "- check_avocado_data                         \u001b[32m✔ Passed\u001b[0m   7 of 7 (100.0 %)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!great_expectations checkpoint run avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to summarize: a checkpoint is a _runnable check_ for your data. They are your first stop for integrating Great Expectations into your pipelines and workflows.\n",
    "For more info on how to do that, refer to the [validation guides](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation.html), or the [workflows and patterns](https://docs.greatexpectations.io/en/latest/guides/workflows_patterns.html) guides.\n",
    "\n",
    "Checkpoints and batches are represented visually below.\n",
    "\n",
    "<img src=\"figures/checkpoint.png\" width=600px>\n",
    "<img src=\"figures/batch.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-profiling\"></a>\n",
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we explored how we could get some metrics about our data using expectations. But what if you don't know what exactly to expect of your data? Well, you could try using Great Expectations' profiling feature, which can try to extract some useful metrics from your data. To try profiling our preconfigured `data_dir` data source, we can use the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHeads up! This feature is Experimental. It may change. Please give us your feedback!\u001b[0m\u001b[0m\n",
      "Profiling 'data_dir' will create expectations and documentation.\u001b[0m\n",
      "            Preparing column 1 of 14: Unnamed: 0\n",
      "            Preparing column 2 of 14: Date\n",
      "            Preparing column 3 of 14: AveragePrice\n",
      "            Preparing column 4 of 14: Total Volume\n",
      "            Preparing column 5 of 14: 4046\n",
      "            Preparing column 6 of 14: 4225\n",
      "            Preparing column 7 of 14: 4770\n",
      "            Preparing column 8 of 14: Total Bags\n",
      "            Preparing column 9 of 14: Small Bags\n",
      "            Preparing column 10 of 14: Large Bags\n",
      "            Preparing column 11 of 14: XLarge Bags\n",
      "            Preparing column 12 of 14: type\n",
      "            Preparing column 13 of 14: year\n",
      "            Preparing column 14 of 14: region\n",
      "\n",
      "\u001b[36m========== Data Docs ==========\u001b[0m\n",
      "\n",
      "Great Expectations is building Data Docs from the data you just profiled!\u001b[0m\n",
      "\n",
      "The following Data Docs sites will be built:\n",
      "\n",
      " - \u001b[36mlocal_site:\u001b[0m file:///Users/quentin.soulet/Documents/Projects/formation/AIclinic-TotalEnergies-tutoQA/great_expectations/uncommitted/data_docs/local_site/index.html\n",
      "\u001b[0m\n",
      "\n",
      "Building Data Docs...\n",
      "\u001b[0m\n",
      "Done building Data Docs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!great_expectations datasource profile data_dir -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running on your own OS, running that command should have opened the freshly built data docs in your browser. If not, you can view the [results from our run](https://datarootsio.github.io/tutorial-great-expectations/profiling). You can find the results in the `Profiling Results` tab. The profiler also generated an expectation suite based on its observations, which you can find in the `Expectation Suites` tab. Be mindful that this is an experimental feature and the generated suite is usually not that helpful, but it could be a good starting point for writing your own.\n",
    "\n",
    "\n",
    "If you'd like to know more about profiling, the [profiling reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/profiling_reference.html) can help you out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-cli\"></a>\n",
    "## The Great Expectations CLI\n",
    "\n",
    "For the purposes of this tutorial, we mostly interacted directly with Great Expectations. If you are going to set up and use Great Expectations for yourself, we recommend using the CLI as much as possible. The concepts should be familiar by now - refer to the  [CLI guide](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/miscellaneous/command_line.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: great_expectations [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Welcome to the great_expectations CLI!\n",
      "\n",
      "  Most commands follow this format: great_expectations <NOUN> <VERB>\n",
      "\n",
      "  The nouns are: datasource, docs, project, suite, validation-operator\n",
      "\n",
      "  Most nouns accept the following verbs: new, list, edit\n",
      "\n",
      "  In particular, the CLI supports the following special commands:\n",
      "\n",
      "  - great_expectations init : create a new great_expectations project\n",
      "\n",
      "  - great_expectations datasource profile : profile a datasource\n",
      "\n",
      "  - great_expectations docs build : compile documentation from expectations\n",
      "\n",
      "Options:\n",
      "  --version      Show the version and exit.\n",
      "  -v, --verbose  Set great_expectations to use verbose output.\n",
      "  --help         Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  checkpoint           Checkpoint operations\n",
      "  datasource           Datasource operations\n",
      "  docs                 Data Docs operations\n",
      "  init                 Initialize a new Great Expectations project.\n",
      "  project              Project operations\n",
      "  store                Store operations\n",
      "  suite                Expectation Suite operations\n",
      "  validation-operator  Validation Operator operations\n"
     ]
    }
   ],
   "source": [
    "!great_expectations --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-setup\"></a>\n",
    "## Setting up your own project\n",
    "\n",
    "To initialize your own project, run `great_expectations init` and follow the instructions. This will scaffold a simple configuration for you, just like the one we provided.\n",
    "\n",
    "Once you created your suite using `great_expectations suite new`, you can use the `great_expectations suite edit` command to open up an auto-generated notebook that you can use to set up your suite. You should be able to recognise the structure of the first part of this notebook a bit ;-)\n",
    "\n",
    "The [getting started guide](https://docs.greatexpectations.io/en/latest/guides/tutorials/getting_started.html) can  help you along the way. For ideas on how Great Expectation can fit into your workflow, check out [Deployment patterns](https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation.html#deployment-patterns).\n",
    "\n",
    "<a id=\"section-conclusion\"></a>\n",
    "## Final words\n",
    "\n",
    "Just to recap, in this tutorial notebook, we started by giving you an overview of the tool and its purpose. We then showed you how to get started with the Python library and define your expectations. We saw that expectations can be bundled as suites, which can be used with validation operators to produce validation results. We had a look at data docs, a clean way to visualize your results and data documentation. We then dived into the data context, showing how the tool is configured. We had a look at checkpoints, which allow you to automate your data testing. We talked a bit about profiling, an experimental feature to generate expectations from given data. Finally, we introduced you to the CLI and set you on the right path to start using Great Expectations right away!\n",
    "\n",
    "We hope you enjoyed the tutorial and wish you all the best in using Great Expectations with your projects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutogx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
